# Chat Context & Smart Provider Selection â€” Implementation Plan

## Problem

The current RAG API is **stateless** â€” each `/ask` request is independent. This causes:
1. No provider selection UI support
2. No conversation history â€” LLM has no memory of prior turns
3. No smart provider inference from context

---

## Architecture Overview

```mermaid
graph LR
    A["ðŸ“± Frontend<br/>(iOS Swift)"] -->|HTTP| B["ðŸ”§ Backend<br/>(Go API)"]
    B -->|HTTP| C["ðŸ§  RAG<br/>(Python FastAPI)"]
    C -->|Query| D["ðŸ“¦ ChromaDB"]
    C -->|Prompt| E["ðŸ¤– LLM"]
```

> [!IMPORTANT]
> Each layer has distinct responsibilities. The Backend acts as a **proxy + session manager**, the RAG handles **retrieval + LLM logic**, and the Frontend handles **UI + session lifecycle**.

---

## ðŸ§  RAG End (Python `main.py`) â€” TODO

> The RAG layer focuses on **retrieval, prompt engineering, and LLM interaction**. It is stateless â€” all session/context is passed in per request.

### Phase 1: New Endpoints

- [ ] **`GET /providers`** â€” Query ChromaDB for distinct `provider` metadata values, return list with display names
  ```json
  {"providers": [
    {"id": "bluecross", "name": "Blue Cross è—åå­—"},
    {"id": "one_degree", "name": "OneDegree"},
    {"id": "prudential", "name": "Prudential ä¿èª "}
  ]}
  ```

- [ ] **Modify `POST /ask`** â€” Accept two new optional fields:
  ```python
  class QueryRequest(BaseModel):
      query: str
      provider: str = None       # Explicit provider filter
      session_id: str = None     # Session ID (passed through from backend)
      chat_history: list = None  # Last N turns [{"role":"user","content":"..."}, ...]
  ```

### Phase 2: Prompt Enhancement

- [ ] **Update prompt template** â€” Add `{chat_history}` and `{active_provider_name}` sections:
  ```
  ### Provider Context
  The user is currently viewing: {active_provider_name}

  ### Conversation History
  {chat_history}

  ### Retrieved Context
  {context}

  ### User Question
  {question}
  ```

- [ ] **Build `format_chat_history()`** â€” Format last 5 turns as `User: ... / Assistant: ...`, truncate answers to 300 chars

- [ ] **Add provider inference prompt rule** â€” If no provider is active and the question seems provider-specific, tell the user which providers are available and suggest selecting one

### Phase 3: Response Enhancement

- [ ] **Update `QueryResponse`** â€” Add `active_provider` and `session_id` to response:
  ```python
  class QueryResponse(BaseModel):
      answer: str
      sources: list[str]
      active_provider: str = None   # Which provider was used for filtering
      session_id: str = None        # Echo back for frontend tracking
  ```

### RAG Summary

| File | Changes |
|---|---|
| `main.py` | Add `/providers` endpoint, modify `/ask` request/response models, update prompt template, add `format_chat_history()` |
| `ingest.py` | No changes needed |

---

## ðŸ”§ Backend End (Go API) â€” TODO

> The Backend is the **session manager and proxy layer**. It owns session state and conversation history, then passes context to the RAG on each call.

### Phase 1: Session Management

- [ ] **Add session store** â€” In-memory map `map[string]*Session` with TTL (30-min expiry):
  ```go
  type Session struct {
      ID               string
      SelectedProvider string          // "" = all providers
      ChatHistory      []ChatTurn      // [{Role, Content}, ...]
      LastActivity     time.Time
      LastMentionedProvider string     // For smart inference
  }
  ```

- [ ] **`POST /api/chat/session`** â€” Create a new session, return `{ session_id }`

- [ ] **`POST /api/chat/session/{id}/provider`** â€” Set/change the active provider for a session. Clear chat history on provider change to avoid cross-provider confusion

- [ ] **`GET /api/chat/providers`** â€” Proxy to RAG's `GET /providers`, cache the result

### Phase 2: Proxy `/ask` with Context

- [ ] **`POST /api/chat/ask`** â€” The main chat endpoint:
  1. Receive `{ session_id, query }` from frontend
  2. Load session â†’ get `selected_provider`, `chat_history`, `last_mentioned_provider`
  3. **Resolve provider** using priority chain:
     ```
     Priority 1: session.SelectedProvider (user chose via UI)
     Priority 2: Detect provider keyword in query
     Priority 3: session.LastMentionedProvider (from prior turns)
     Priority 4: nil â†’ search all providers
     ```
  4. Forward to RAG: `POST /ask { query, provider, session_id, chat_history (last 5 turns) }`
  5. Save the turn (user query + LLM answer) to `session.ChatHistory`
  6. If a provider was detected in the query, update `session.LastMentionedProvider`
  7. Return response to frontend with `active_provider`

- [ ] **Provider keyword detection** â€” Utility function:
  ```go
  func detectProvider(query string) string {
      lower := strings.ToLower(query)
      switch {
      case contains(lower, "blue cross", "bluecross", "è—åå­—"): return "bluecross"
      case contains(lower, "one degree", "onedegree"):           return "one_degree"
      case contains(lower, "prudential", "pruchoice", "ä¿èª "):   return "prudential"
      case contains(lower, "bolttech"):                          return "bolttech"
      default: return ""
      }
  }
  ```

### Phase 3: Session Cleanup

- [ ] **Background goroutine** â€” Every 5 minutes, sweep expired sessions (idle > 30 min)

### Backend Summary

| File | Changes |
|---|---|
| `internal/chat/session.go` | `Session` struct, in-memory store, TTL cleanup |
| `internal/chat/handler.go` | HTTP handlers for `/session`, `/session/{id}/provider`, `/ask` |
| `internal/chat/provider.go` | Provider detection + resolution logic |
| `cmd/server/main.go` | Register new chat routes |

---

## ðŸ“± Frontend End (iOS Swift) â€” TODO

> The Frontend manages the **UI and session lifecycle**. It creates sessions, lets users pick providers, and sends queries with session IDs.

### Phase 1: Provider Selection UI

- [ ] **Provider selection chips/buttons** â€” Show at the top of the chat view (or in a sheet):
  - Fetch from `GET /api/chat/providers` on view appear
  - Options: "All Providers" (default), "Blue Cross", "OneDegree", "Prudential", etc.
  - Tapping a chip â†’ calls `POST /api/chat/session/{id}/provider`
  - Selected chip shows highlighted state

- [ ] **Session lifecycle** â€” Create a session `onAppear`:
  ```swift
  // On chat view appear
  let session = await api.createSession() // POST /api/chat/session
  self.sessionId = session.id
  ```
  
### Phase 2: Chat with Context

- [ ] **Send `session_id` with every query**:
  ```swift
  let response = await api.ask(
      query: userMessage,
      sessionId: self.sessionId
  )
  ```
  - No need to manage chat history on the frontend â€” the Backend handles it

- [ ] **Display active provider indicator** â€” Show a badge/label from `response.active_provider`:
  - e.g., "ðŸ” Answering based on: **Prudential**" above the response bubble

### Phase 3: Smart Inference UI Feedback

- [ ] **Show provider context** â€” When `active_provider` comes back in the response, show which provider the system is using
- [ ] **Provider switch indicator** â€” If the user mentions a different provider mid-conversation, show a subtle notification: "Switched to Blue Cross context"

### Frontend Summary

| File | Changes |
|---|---|
| `RAGChatView.swift` | Add provider chips, session management, active provider display |
| `InsuranceAPIService.swift` | Add `createSession()`, `selectProvider()`, update `askQuestion()` to include `sessionId` |

---

## Data Flow Diagrams

### Normal Query (Provider Pre-Selected)

```mermaid
sequenceDiagram
    participant F as ðŸ“± Frontend
    participant B as ðŸ”§ Backend (Go)
    participant R as ðŸ§  RAG (Python)

    F->>B: POST /api/chat/session
    B-->>F: { session_id }

    F->>B: POST /session/{id}/provider { "prudential" }
    B-->>F: 200 OK

    F->>B: POST /api/chat/ask { session_id, query }
    B->>B: Load session â†’ provider=prudential, history=[]
    B->>R: POST /ask { query, provider:"prudential", chat_history:[] }
    R->>R: Filter ChromaDB by provider, inject into prompt
    R-->>B: { answer, sources, active_provider:"prudential" }
    B->>B: Save turn to session.ChatHistory
    B-->>F: { answer, sources, active_provider:"prudential" }
```

### Follow-up Query (Smart Inference)

```mermaid
sequenceDiagram
    participant F as ðŸ“± Frontend
    participant B as ðŸ”§ Backend (Go)
    participant R as ðŸ§  RAG (Python)

    Note over F: User already asked about Prudential in Turn 1

    F->>B: POST /api/chat/ask { session_id, "What is the waiting period?" }
    B->>B: No provider in query, no UI selection
    B->>B: âœ… session.LastMentionedProvider = "prudential"
    B->>R: POST /ask { query, provider:"prudential", chat_history:[Turn1] }
    R-->>B: { answer about Prudential waiting period }
    B-->>F: { answer, active_provider:"prudential" }
```

---

## Implementation Order

| Priority | Task | Owner | Depends On |
|---|---|---|---|
| 1 | `GET /providers` endpoint | ðŸ§  RAG | â€” |
| 2 | `POST /ask` accept `chat_history` + `session_id` | ðŸ§  RAG | â€” |
| 3 | Update prompt template | ðŸ§  RAG | #2 |
| 4 | Update `QueryResponse` model | ðŸ§  RAG | â€” |
| 5 | Session store + CRUD endpoints | ðŸ”§ Backend | #1 |
| 6 | Proxy `/ask` with context injection | ðŸ”§ Backend | #2, #5 |
| 7 | Provider resolution logic | ðŸ”§ Backend | #6 |
| 8 | Provider selection UI | ðŸ“± Frontend | #5 |
| 9 | Chat with `session_id` | ðŸ“± Frontend | #6 |
| 10 | Active provider indicator | ðŸ“± Frontend | #7 |

> [!TIP]
> **Start with RAG (#1-4)** since both Backend and Frontend depend on it. Backend (#5-7) and Frontend (#8-10) can then be developed in parallel.

---

## Verification Plan

### Per-Layer Tests

| Layer | Test | Method |
|---|---|---|
| ðŸ§  RAG | `/providers` returns all 3 providers | `curl GET /providers` |
| ðŸ§  RAG | `/ask` with `chat_history` produces context-aware answer | `curl POST /ask` with history |
| ðŸ”§ Backend | Session CRUD works (create, select provider, expire) | `curl` + wait 30min |
| ðŸ”§ Backend | Provider priority chain resolves correctly | Unit test `resolveProvider()` |
| ðŸ“± Frontend | Provider chips render and toggle | Manual UI test |
| ðŸ“± Frontend | Follow-up questions maintain provider context | Manual conversation test |

### End-to-End Test

1. Open chat â†’ provider chips load
2. Select "Prudential" â†’ chip highlights
3. Ask "What are the age requirements?" â†’ Answer references Prudential, sources show `prudential.md`
4. Ask "What about the waiting period?" (no provider mentioned) â†’ Still answers about Prudential
5. Ask "How does Blue Cross compare?" â†’ Switches context to Blue Cross
6. Ask "And the coverage limit?" â†’ Still about Blue Cross (inferred from Turn 5)
